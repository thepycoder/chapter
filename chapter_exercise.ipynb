{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter_exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sZ8nPbcnrOBq"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ8nPbcnrOBq",
        "colab_type": "text"
      },
      "source": [
        "# First get the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAPDSNK0rKcv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bfecf3bf-0386-4bdb-df45-e37f1c40168c"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.names\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
        "\n",
        "!unzip \"UCI HAR Dataset.zip\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-20 10:04:59--  https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.names\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6304 (6.2K) [application/x-httpd-php]\n",
            "Saving to: ‘UCI HAR Dataset.names’\n",
            "\n",
            "UCI HAR Dataset.nam 100%[===================>]   6.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-12-20 10:05:00 (131 MB/s) - ‘UCI HAR Dataset.names’ saved [6304/6304]\n",
            "\n",
            "--2019-12-20 10:05:01--  https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60999314 (58M) [application/x-httpd-php]\n",
            "Saving to: ‘UCI HAR Dataset.zip’\n",
            "\n",
            "UCI HAR Dataset.zip 100%[===================>]  58.17M  15.7MB/s    in 3.7s    \n",
            "\n",
            "2019-12-20 10:05:06 (15.7 MB/s) - ‘UCI HAR Dataset.zip’ saved [60999314/60999314]\n",
            "\n",
            "Archive:  UCI HAR Dataset.zip\n",
            "   creating: UCI HAR Dataset/\n",
            "  inflating: UCI HAR Dataset/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/UCI HAR Dataset/\n",
            "  inflating: __MACOSX/UCI HAR Dataset/._.DS_Store  \n",
            "  inflating: UCI HAR Dataset/activity_labels.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/._activity_labels.txt  \n",
            "  inflating: UCI HAR Dataset/features.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/._features.txt  \n",
            "  inflating: UCI HAR Dataset/features_info.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/._features_info.txt  \n",
            "  inflating: UCI HAR Dataset/README.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/._README.txt  \n",
            "   creating: UCI HAR Dataset/test/\n",
            "   creating: UCI HAR Dataset/test/Inertial Signals/\n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/body_acc_x_test.txt  \n",
            "   creating: __MACOSX/UCI HAR Dataset/test/\n",
            "   creating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/\n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_acc_x_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/body_acc_y_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_acc_y_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/body_acc_z_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_acc_z_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/body_gyro_x_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_gyro_x_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/body_gyro_y_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_gyro_y_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/body_gyro_z_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._body_gyro_z_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/total_acc_x_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._total_acc_x_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/total_acc_y_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._total_acc_y_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/Inertial Signals/total_acc_z_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/Inertial Signals/._total_acc_z_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/._Inertial Signals  \n",
            "  inflating: UCI HAR Dataset/test/subject_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/._subject_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/X_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/._X_test.txt  \n",
            "  inflating: UCI HAR Dataset/test/y_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/test/._y_test.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/._test  \n",
            "   creating: UCI HAR Dataset/train/\n",
            "   creating: UCI HAR Dataset/train/Inertial Signals/\n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/body_acc_x_train.txt  \n",
            "   creating: __MACOSX/UCI HAR Dataset/train/\n",
            "   creating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/\n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_acc_x_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/body_acc_y_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_acc_y_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/body_acc_z_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_acc_z_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/body_gyro_x_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_gyro_x_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/body_gyro_y_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_gyro_y_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/body_gyro_z_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._body_gyro_z_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/total_acc_x_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._total_acc_x_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/total_acc_y_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._total_acc_y_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/Inertial Signals/total_acc_z_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/Inertial Signals/._total_acc_z_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/._Inertial Signals  \n",
            "  inflating: UCI HAR Dataset/train/subject_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/._subject_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/X_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/._X_train.txt  \n",
            "  inflating: UCI HAR Dataset/train/y_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/train/._y_train.txt  \n",
            "  inflating: __MACOSX/UCI HAR Dataset/._train  \n",
            "  inflating: __MACOSX/._UCI HAR Dataset  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ51PCUircPD",
        "colab_type": "text"
      },
      "source": [
        "# Get some helper functions ready"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RHPEUz3X2TL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miUguv1urbhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels=['LAYING', 'SITTING','STANDING','WALKING','WALKING_DOWNSTAIRS','WALKING_UPSTAIRS']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taLbP8Jjrga4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PmluyFErilp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perform_model(model, X_train, y_train, X_test, y_test, class_labels, cm_normalize=True, \\\n",
        "                 print_cm=True, cm_cmap=plt.cm.Greens):\n",
        "    \n",
        "    # to store results at various phases\n",
        "    results = dict()\n",
        "    \n",
        "    # time at which model starts training \n",
        "    train_start_time = datetime.now()\n",
        "    print('training the model..')\n",
        "    model.fit(X_train, y_train)\n",
        "    print('Done \\n \\n')\n",
        "    train_end_time = datetime.now()\n",
        "    results['training_time'] =  train_end_time - train_start_time\n",
        "    print('training_time(HH:MM:SS.ms) - {}\\n\\n'.format(results['training_time']))\n",
        "    \n",
        "    \n",
        "    # predict test data\n",
        "    print('Predicting test data')\n",
        "    test_start_time = datetime.now()\n",
        "    y_pred = model.predict(X_test)\n",
        "    test_end_time = datetime.now()\n",
        "    print('Done \\n \\n')\n",
        "    results['testing_time'] = test_end_time - test_start_time\n",
        "    print('testing time(HH:MM:SS:ms) - {}\\n\\n'.format(results['testing_time']))\n",
        "    results['predicted'] = y_pred\n",
        "   \n",
        "\n",
        "    # calculate overall accuracty of the model\n",
        "    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "    # store accuracy in results\n",
        "    results['accuracy'] = accuracy\n",
        "    print('---------------------')\n",
        "    print('|      Accuracy      |')\n",
        "    print('---------------------')\n",
        "    print('\\n    {}\\n\\n'.format(accuracy))\n",
        "    \n",
        "    \n",
        "    # confusion matrix\n",
        "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "    results['confusion_matrix'] = cm\n",
        "    if print_cm: \n",
        "        print('--------------------')\n",
        "        print('| Confusion Matrix |')\n",
        "        print('--------------------')\n",
        "        print('\\n {}'.format(cm))\n",
        "        \n",
        "    # plot confusin matrix\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.grid(b=False)\n",
        "    plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix', cmap = cm_cmap)\n",
        "    plt.show()\n",
        "    \n",
        "    # get classification report\n",
        "    print('-------------------------')\n",
        "    print('| Classifiction Report |')\n",
        "    print('-------------------------')\n",
        "    classification_report = metrics.classification_report(y_test, y_pred)\n",
        "    # store report in results\n",
        "    results['classification_report'] = classification_report\n",
        "    print(classification_report)\n",
        "    \n",
        "    # add the trained  model to the results\n",
        "    results['model'] = model\n",
        "    \n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFOP-Y4QsYZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Activities are the class labels\n",
        "# It is a 6 class classification\n",
        "ACTIVITIES = {\n",
        "    0: 'WALKING',\n",
        "    1: 'WALKING_UPSTAIRS',\n",
        "    2: 'WALKING_DOWNSTAIRS',\n",
        "    3: 'SITTING',\n",
        "    4: 'STANDING',\n",
        "    5: 'LAYING',\n",
        "}\n",
        "\n",
        "# Utility function to print the confusion matrix\n",
        "def confusion_matrix(Y_true, Y_pred):\n",
        "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
        "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
        "\n",
        "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])\n",
        "\n",
        "# Utility function to print the confusion matrix\n",
        "def confusion_matrix_raw(Y_true, Y_pred):\n",
        "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
        "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
        "\n",
        "    #return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])\n",
        "    return metrics.confusion_matrix(Y_true, Y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kiza4a2TsVTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data directory\n",
        "DATADIR = 'UCI HAR Dataset'\n",
        "# Raw data signals\n",
        "# Signals are from Accelerometer and Gyroscope\n",
        "# The signals are in x,y,z directions\n",
        "# Sensor signals are filtered to have only body acceleration\n",
        "# excluding the acceleration due to gravity\n",
        "# Triaxial acceleration from the accelerometer is total acceleration\n",
        "SIGNALS = [\n",
        "    \"body_acc_x\",\n",
        "    \"body_acc_y\",\n",
        "    \"body_acc_z\",\n",
        "    \"body_gyro_x\",\n",
        "    \"body_gyro_y\",\n",
        "    \"body_gyro_z\",\n",
        "    \"total_acc_x\",\n",
        "    \"total_acc_y\",\n",
        "    \"total_acc_z\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBibvWdFlq1y",
        "colab_type": "text"
      },
      "source": [
        "# Load in the data for the baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE6KbqNWl98z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2e11b68-2115-4978-a989-963a499b4e84"
      },
      "source": [
        "# get the features from the file features.txt\n",
        "features = list()\n",
        "with open('UCI HAR Dataset/features.txt') as f:\n",
        "    features = [line.split()[0] + '_' + line.split()[1] for line in f.readlines()]\n",
        "print('No of Features: {}'.format(len(features)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of Features: 561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR6R6xRolyak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "540ab2dc-480f-475f-cea6-4adb8c9ddea8"
      },
      "source": [
        "# get the data from txt files to pandas dataffame\n",
        "X_train = pd.read_csv('UCI HAR Dataset/train/X_train.txt', delim_whitespace=True, header=None, names=features)\n",
        "\n",
        "# add subject column to the dataframe\n",
        "X_train['subject'] = pd.read_csv('UCI HAR Dataset/train/subject_train.txt', header=None, squeeze=True)\n",
        "\n",
        "y_train = pd.read_csv('UCI HAR Dataset/train/y_train.txt', names=['Activity'], squeeze=True)\n",
        "y_train_labels = y_train.map({1: 'WALKING', 2:'WALKING_UPSTAIRS', 3:'WALKING_DOWNSTAIRS', 4:'SITTING', 5:'STANDING', 6:'LAYING'})\n",
        "\n",
        "# put all columns in a single dataframe\n",
        "train = X_train\n",
        "train['Activity'] = y_train\n",
        "train['ActivityName'] = y_train_labels\n",
        "train.sample()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1_tBodyAcc-mean()-X</th>\n",
              "      <th>2_tBodyAcc-mean()-Y</th>\n",
              "      <th>3_tBodyAcc-mean()-Z</th>\n",
              "      <th>4_tBodyAcc-std()-X</th>\n",
              "      <th>5_tBodyAcc-std()-Y</th>\n",
              "      <th>6_tBodyAcc-std()-Z</th>\n",
              "      <th>7_tBodyAcc-mad()-X</th>\n",
              "      <th>8_tBodyAcc-mad()-Y</th>\n",
              "      <th>9_tBodyAcc-mad()-Z</th>\n",
              "      <th>10_tBodyAcc-max()-X</th>\n",
              "      <th>11_tBodyAcc-max()-Y</th>\n",
              "      <th>12_tBodyAcc-max()-Z</th>\n",
              "      <th>13_tBodyAcc-min()-X</th>\n",
              "      <th>14_tBodyAcc-min()-Y</th>\n",
              "      <th>15_tBodyAcc-min()-Z</th>\n",
              "      <th>16_tBodyAcc-sma()</th>\n",
              "      <th>17_tBodyAcc-energy()-X</th>\n",
              "      <th>18_tBodyAcc-energy()-Y</th>\n",
              "      <th>19_tBodyAcc-energy()-Z</th>\n",
              "      <th>20_tBodyAcc-iqr()-X</th>\n",
              "      <th>21_tBodyAcc-iqr()-Y</th>\n",
              "      <th>22_tBodyAcc-iqr()-Z</th>\n",
              "      <th>23_tBodyAcc-entropy()-X</th>\n",
              "      <th>24_tBodyAcc-entropy()-Y</th>\n",
              "      <th>25_tBodyAcc-entropy()-Z</th>\n",
              "      <th>26_tBodyAcc-arCoeff()-X,1</th>\n",
              "      <th>27_tBodyAcc-arCoeff()-X,2</th>\n",
              "      <th>28_tBodyAcc-arCoeff()-X,3</th>\n",
              "      <th>29_tBodyAcc-arCoeff()-X,4</th>\n",
              "      <th>30_tBodyAcc-arCoeff()-Y,1</th>\n",
              "      <th>31_tBodyAcc-arCoeff()-Y,2</th>\n",
              "      <th>32_tBodyAcc-arCoeff()-Y,3</th>\n",
              "      <th>33_tBodyAcc-arCoeff()-Y,4</th>\n",
              "      <th>34_tBodyAcc-arCoeff()-Z,1</th>\n",
              "      <th>35_tBodyAcc-arCoeff()-Z,2</th>\n",
              "      <th>36_tBodyAcc-arCoeff()-Z,3</th>\n",
              "      <th>37_tBodyAcc-arCoeff()-Z,4</th>\n",
              "      <th>38_tBodyAcc-correlation()-X,Y</th>\n",
              "      <th>39_tBodyAcc-correlation()-X,Z</th>\n",
              "      <th>40_tBodyAcc-correlation()-Y,Z</th>\n",
              "      <th>...</th>\n",
              "      <th>525_fBodyBodyAccJerkMag-maxInds</th>\n",
              "      <th>526_fBodyBodyAccJerkMag-meanFreq()</th>\n",
              "      <th>527_fBodyBodyAccJerkMag-skewness()</th>\n",
              "      <th>528_fBodyBodyAccJerkMag-kurtosis()</th>\n",
              "      <th>529_fBodyBodyGyroMag-mean()</th>\n",
              "      <th>530_fBodyBodyGyroMag-std()</th>\n",
              "      <th>531_fBodyBodyGyroMag-mad()</th>\n",
              "      <th>532_fBodyBodyGyroMag-max()</th>\n",
              "      <th>533_fBodyBodyGyroMag-min()</th>\n",
              "      <th>534_fBodyBodyGyroMag-sma()</th>\n",
              "      <th>535_fBodyBodyGyroMag-energy()</th>\n",
              "      <th>536_fBodyBodyGyroMag-iqr()</th>\n",
              "      <th>537_fBodyBodyGyroMag-entropy()</th>\n",
              "      <th>538_fBodyBodyGyroMag-maxInds</th>\n",
              "      <th>539_fBodyBodyGyroMag-meanFreq()</th>\n",
              "      <th>540_fBodyBodyGyroMag-skewness()</th>\n",
              "      <th>541_fBodyBodyGyroMag-kurtosis()</th>\n",
              "      <th>542_fBodyBodyGyroJerkMag-mean()</th>\n",
              "      <th>543_fBodyBodyGyroJerkMag-std()</th>\n",
              "      <th>544_fBodyBodyGyroJerkMag-mad()</th>\n",
              "      <th>545_fBodyBodyGyroJerkMag-max()</th>\n",
              "      <th>546_fBodyBodyGyroJerkMag-min()</th>\n",
              "      <th>547_fBodyBodyGyroJerkMag-sma()</th>\n",
              "      <th>548_fBodyBodyGyroJerkMag-energy()</th>\n",
              "      <th>549_fBodyBodyGyroJerkMag-iqr()</th>\n",
              "      <th>550_fBodyBodyGyroJerkMag-entropy()</th>\n",
              "      <th>551_fBodyBodyGyroJerkMag-maxInds</th>\n",
              "      <th>552_fBodyBodyGyroJerkMag-meanFreq()</th>\n",
              "      <th>553_fBodyBodyGyroJerkMag-skewness()</th>\n",
              "      <th>554_fBodyBodyGyroJerkMag-kurtosis()</th>\n",
              "      <th>555_angle(tBodyAccMean,gravity)</th>\n",
              "      <th>556_angle(tBodyAccJerkMean),gravityMean)</th>\n",
              "      <th>557_angle(tBodyGyroMean,gravityMean)</th>\n",
              "      <th>558_angle(tBodyGyroJerkMean,gravityMean)</th>\n",
              "      <th>559_angle(X,gravityMean)</th>\n",
              "      <th>560_angle(Y,gravityMean)</th>\n",
              "      <th>561_angle(Z,gravityMean)</th>\n",
              "      <th>subject</th>\n",
              "      <th>Activity</th>\n",
              "      <th>ActivityName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2046</th>\n",
              "      <td>0.245567</td>\n",
              "      <td>-0.022919</td>\n",
              "      <td>-0.111754</td>\n",
              "      <td>-0.307961</td>\n",
              "      <td>-0.130955</td>\n",
              "      <td>-0.152379</td>\n",
              "      <td>-0.348899</td>\n",
              "      <td>-0.120308</td>\n",
              "      <td>-0.126794</td>\n",
              "      <td>-0.158359</td>\n",
              "      <td>-0.207061</td>\n",
              "      <td>-0.078938</td>\n",
              "      <td>0.296522</td>\n",
              "      <td>0.156763</td>\n",
              "      <td>0.579016</td>\n",
              "      <td>-0.146039</td>\n",
              "      <td>-0.759017</td>\n",
              "      <td>-0.853404</td>\n",
              "      <td>-0.676117</td>\n",
              "      <td>-0.521043</td>\n",
              "      <td>-0.295085</td>\n",
              "      <td>-0.081851</td>\n",
              "      <td>0.334088</td>\n",
              "      <td>0.36091</td>\n",
              "      <td>-0.061878</td>\n",
              "      <td>-0.60423</td>\n",
              "      <td>0.4011</td>\n",
              "      <td>-0.022951</td>\n",
              "      <td>-0.042902</td>\n",
              "      <td>-0.208757</td>\n",
              "      <td>0.106921</td>\n",
              "      <td>0.097941</td>\n",
              "      <td>0.104978</td>\n",
              "      <td>-0.719962</td>\n",
              "      <td>0.572389</td>\n",
              "      <td>-0.510932</td>\n",
              "      <td>0.258412</td>\n",
              "      <td>-0.374862</td>\n",
              "      <td>-0.014502</td>\n",
              "      <td>-0.087568</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.904762</td>\n",
              "      <td>-0.023681</td>\n",
              "      <td>0.058203</td>\n",
              "      <td>-0.256384</td>\n",
              "      <td>-0.560808</td>\n",
              "      <td>-0.278531</td>\n",
              "      <td>-0.397612</td>\n",
              "      <td>-0.311572</td>\n",
              "      <td>-0.769317</td>\n",
              "      <td>-0.560808</td>\n",
              "      <td>-0.756559</td>\n",
              "      <td>-0.674005</td>\n",
              "      <td>0.199544</td>\n",
              "      <td>-0.846154</td>\n",
              "      <td>-0.416147</td>\n",
              "      <td>0.057984</td>\n",
              "      <td>-0.371473</td>\n",
              "      <td>-0.79852</td>\n",
              "      <td>-0.828301</td>\n",
              "      <td>-0.786702</td>\n",
              "      <td>-0.856469</td>\n",
              "      <td>-0.968714</td>\n",
              "      <td>-0.79852</td>\n",
              "      <td>-0.980494</td>\n",
              "      <td>-0.738075</td>\n",
              "      <td>0.128673</td>\n",
              "      <td>-0.777778</td>\n",
              "      <td>0.058765</td>\n",
              "      <td>-0.529902</td>\n",
              "      <td>-0.806119</td>\n",
              "      <td>0.527447</td>\n",
              "      <td>-0.675423</td>\n",
              "      <td>0.643123</td>\n",
              "      <td>0.769014</td>\n",
              "      <td>-0.629196</td>\n",
              "      <td>0.329779</td>\n",
              "      <td>-0.092016</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>WALKING_UPSTAIRS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 564 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      1_tBodyAcc-mean()-X  2_tBodyAcc-mean()-Y  ...  Activity      ActivityName\n",
              "2046             0.245567            -0.022919  ...         2  WALKING_UPSTAIRS\n",
              "\n",
              "[1 rows x 564 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6LMoC9rmCNX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "62805944-6107-4ef4-ad79-62e4a86599ec"
      },
      "source": [
        "# get the data from txt files to pandas dataffame\n",
        "X_test = pd.read_csv('UCI HAR Dataset/test/X_test.txt', delim_whitespace=True, header=None, names=features)\n",
        "\n",
        "# add subject column to the dataframe\n",
        "X_test['subject'] = pd.read_csv('UCI HAR Dataset/test/subject_test.txt', header=None, squeeze=True)\n",
        "\n",
        "# get y labels from the txt file\n",
        "y_test = pd.read_csv('UCI HAR Dataset/test/y_test.txt', names=['Activity'], squeeze=True)\n",
        "y_test_labels = y_test.map({1: 'WALKING', 2:'WALKING_UPSTAIRS',3:'WALKING_DOWNSTAIRS',\\\n",
        "                       4:'SITTING', 5:'STANDING',6:'LAYING'})\n",
        "\n",
        "\n",
        "# put all columns in a single dataframe\n",
        "test = X_test\n",
        "test['Activity'] = y_test\n",
        "test['ActivityName'] = y_test_labels\n",
        "test.sample()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1_tBodyAcc-mean()-X</th>\n",
              "      <th>2_tBodyAcc-mean()-Y</th>\n",
              "      <th>3_tBodyAcc-mean()-Z</th>\n",
              "      <th>4_tBodyAcc-std()-X</th>\n",
              "      <th>5_tBodyAcc-std()-Y</th>\n",
              "      <th>6_tBodyAcc-std()-Z</th>\n",
              "      <th>7_tBodyAcc-mad()-X</th>\n",
              "      <th>8_tBodyAcc-mad()-Y</th>\n",
              "      <th>9_tBodyAcc-mad()-Z</th>\n",
              "      <th>10_tBodyAcc-max()-X</th>\n",
              "      <th>11_tBodyAcc-max()-Y</th>\n",
              "      <th>12_tBodyAcc-max()-Z</th>\n",
              "      <th>13_tBodyAcc-min()-X</th>\n",
              "      <th>14_tBodyAcc-min()-Y</th>\n",
              "      <th>15_tBodyAcc-min()-Z</th>\n",
              "      <th>16_tBodyAcc-sma()</th>\n",
              "      <th>17_tBodyAcc-energy()-X</th>\n",
              "      <th>18_tBodyAcc-energy()-Y</th>\n",
              "      <th>19_tBodyAcc-energy()-Z</th>\n",
              "      <th>20_tBodyAcc-iqr()-X</th>\n",
              "      <th>21_tBodyAcc-iqr()-Y</th>\n",
              "      <th>22_tBodyAcc-iqr()-Z</th>\n",
              "      <th>23_tBodyAcc-entropy()-X</th>\n",
              "      <th>24_tBodyAcc-entropy()-Y</th>\n",
              "      <th>25_tBodyAcc-entropy()-Z</th>\n",
              "      <th>26_tBodyAcc-arCoeff()-X,1</th>\n",
              "      <th>27_tBodyAcc-arCoeff()-X,2</th>\n",
              "      <th>28_tBodyAcc-arCoeff()-X,3</th>\n",
              "      <th>29_tBodyAcc-arCoeff()-X,4</th>\n",
              "      <th>30_tBodyAcc-arCoeff()-Y,1</th>\n",
              "      <th>31_tBodyAcc-arCoeff()-Y,2</th>\n",
              "      <th>32_tBodyAcc-arCoeff()-Y,3</th>\n",
              "      <th>33_tBodyAcc-arCoeff()-Y,4</th>\n",
              "      <th>34_tBodyAcc-arCoeff()-Z,1</th>\n",
              "      <th>35_tBodyAcc-arCoeff()-Z,2</th>\n",
              "      <th>36_tBodyAcc-arCoeff()-Z,3</th>\n",
              "      <th>37_tBodyAcc-arCoeff()-Z,4</th>\n",
              "      <th>38_tBodyAcc-correlation()-X,Y</th>\n",
              "      <th>39_tBodyAcc-correlation()-X,Z</th>\n",
              "      <th>40_tBodyAcc-correlation()-Y,Z</th>\n",
              "      <th>...</th>\n",
              "      <th>525_fBodyBodyAccJerkMag-maxInds</th>\n",
              "      <th>526_fBodyBodyAccJerkMag-meanFreq()</th>\n",
              "      <th>527_fBodyBodyAccJerkMag-skewness()</th>\n",
              "      <th>528_fBodyBodyAccJerkMag-kurtosis()</th>\n",
              "      <th>529_fBodyBodyGyroMag-mean()</th>\n",
              "      <th>530_fBodyBodyGyroMag-std()</th>\n",
              "      <th>531_fBodyBodyGyroMag-mad()</th>\n",
              "      <th>532_fBodyBodyGyroMag-max()</th>\n",
              "      <th>533_fBodyBodyGyroMag-min()</th>\n",
              "      <th>534_fBodyBodyGyroMag-sma()</th>\n",
              "      <th>535_fBodyBodyGyroMag-energy()</th>\n",
              "      <th>536_fBodyBodyGyroMag-iqr()</th>\n",
              "      <th>537_fBodyBodyGyroMag-entropy()</th>\n",
              "      <th>538_fBodyBodyGyroMag-maxInds</th>\n",
              "      <th>539_fBodyBodyGyroMag-meanFreq()</th>\n",
              "      <th>540_fBodyBodyGyroMag-skewness()</th>\n",
              "      <th>541_fBodyBodyGyroMag-kurtosis()</th>\n",
              "      <th>542_fBodyBodyGyroJerkMag-mean()</th>\n",
              "      <th>543_fBodyBodyGyroJerkMag-std()</th>\n",
              "      <th>544_fBodyBodyGyroJerkMag-mad()</th>\n",
              "      <th>545_fBodyBodyGyroJerkMag-max()</th>\n",
              "      <th>546_fBodyBodyGyroJerkMag-min()</th>\n",
              "      <th>547_fBodyBodyGyroJerkMag-sma()</th>\n",
              "      <th>548_fBodyBodyGyroJerkMag-energy()</th>\n",
              "      <th>549_fBodyBodyGyroJerkMag-iqr()</th>\n",
              "      <th>550_fBodyBodyGyroJerkMag-entropy()</th>\n",
              "      <th>551_fBodyBodyGyroJerkMag-maxInds</th>\n",
              "      <th>552_fBodyBodyGyroJerkMag-meanFreq()</th>\n",
              "      <th>553_fBodyBodyGyroJerkMag-skewness()</th>\n",
              "      <th>554_fBodyBodyGyroJerkMag-kurtosis()</th>\n",
              "      <th>555_angle(tBodyAccMean,gravity)</th>\n",
              "      <th>556_angle(tBodyAccJerkMean),gravityMean)</th>\n",
              "      <th>557_angle(tBodyGyroMean,gravityMean)</th>\n",
              "      <th>558_angle(tBodyGyroJerkMean,gravityMean)</th>\n",
              "      <th>559_angle(X,gravityMean)</th>\n",
              "      <th>560_angle(Y,gravityMean)</th>\n",
              "      <th>561_angle(Z,gravityMean)</th>\n",
              "      <th>subject</th>\n",
              "      <th>Activity</th>\n",
              "      <th>ActivityName</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1949</th>\n",
              "      <td>0.28271</td>\n",
              "      <td>-0.016633</td>\n",
              "      <td>-0.110989</td>\n",
              "      <td>-0.992354</td>\n",
              "      <td>-0.991923</td>\n",
              "      <td>-0.993821</td>\n",
              "      <td>-0.992461</td>\n",
              "      <td>-0.99124</td>\n",
              "      <td>-0.994951</td>\n",
              "      <td>-0.936639</td>\n",
              "      <td>-0.570515</td>\n",
              "      <td>-0.823865</td>\n",
              "      <td>0.848283</td>\n",
              "      <td>0.691926</td>\n",
              "      <td>0.839352</td>\n",
              "      <td>-0.993887</td>\n",
              "      <td>-0.999933</td>\n",
              "      <td>-0.999956</td>\n",
              "      <td>-0.999891</td>\n",
              "      <td>-0.991938</td>\n",
              "      <td>-0.991322</td>\n",
              "      <td>-0.996053</td>\n",
              "      <td>-0.471846</td>\n",
              "      <td>-0.663894</td>\n",
              "      <td>-0.706222</td>\n",
              "      <td>0.234433</td>\n",
              "      <td>-0.094051</td>\n",
              "      <td>0.152271</td>\n",
              "      <td>0.062948</td>\n",
              "      <td>0.194435</td>\n",
              "      <td>-0.01653</td>\n",
              "      <td>0.098529</td>\n",
              "      <td>0.157763</td>\n",
              "      <td>0.126672</td>\n",
              "      <td>0.027743</td>\n",
              "      <td>0.008753</td>\n",
              "      <td>0.028893</td>\n",
              "      <td>-0.132365</td>\n",
              "      <td>-0.092219</td>\n",
              "      <td>-0.050282</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.650794</td>\n",
              "      <td>0.372277</td>\n",
              "      <td>-0.737509</td>\n",
              "      <td>-0.95394</td>\n",
              "      <td>-0.987835</td>\n",
              "      <td>-0.990439</td>\n",
              "      <td>-0.988476</td>\n",
              "      <td>-0.992518</td>\n",
              "      <td>-0.996827</td>\n",
              "      <td>-0.987835</td>\n",
              "      <td>-0.999889</td>\n",
              "      <td>-0.986804</td>\n",
              "      <td>-0.736521</td>\n",
              "      <td>-0.897436</td>\n",
              "      <td>0.168983</td>\n",
              "      <td>-0.634417</td>\n",
              "      <td>-0.87119</td>\n",
              "      <td>-0.992227</td>\n",
              "      <td>-0.992227</td>\n",
              "      <td>-0.991743</td>\n",
              "      <td>-0.993736</td>\n",
              "      <td>-0.993386</td>\n",
              "      <td>-0.992227</td>\n",
              "      <td>-0.999946</td>\n",
              "      <td>-0.995103</td>\n",
              "      <td>-0.923452</td>\n",
              "      <td>-0.968254</td>\n",
              "      <td>0.132862</td>\n",
              "      <td>-0.406681</td>\n",
              "      <td>-0.793117</td>\n",
              "      <td>-0.081971</td>\n",
              "      <td>0.251379</td>\n",
              "      <td>-0.220999</td>\n",
              "      <td>-0.530747</td>\n",
              "      <td>0.369271</td>\n",
              "      <td>-0.727066</td>\n",
              "      <td>-0.218609</td>\n",
              "      <td>18</td>\n",
              "      <td>6</td>\n",
              "      <td>LAYING</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 564 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      1_tBodyAcc-mean()-X  2_tBodyAcc-mean()-Y  ...  Activity  ActivityName\n",
              "1949              0.28271            -0.016633  ...         6        LAYING\n",
              "\n",
              "[1 rows x 564 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjl2bhkdpG4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get X_train and y_train from csv files\n",
        "X_train = train.drop(['subject', 'Activity', 'ActivityName'], axis=1)\n",
        "y_train = train.ActivityName"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMxDehzmpKuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get X_test and y_test from test csv file\n",
        "X_test = test.drop(['subject', 'Activity', 'ActivityName'], axis=1)\n",
        "y_test = test.ActivityName"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WG-5TZGsA-N",
        "colab_type": "text"
      },
      "source": [
        "# Load in the raw signal data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRmjnnc8sL4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_y(subset):\n",
        "    \"\"\"\n",
        "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
        "    that represents a human activity. We return a binary representation of \n",
        "    every sample objective as a 6 bits vector using One Hot Encoding\n",
        "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
        "    \"\"\"\n",
        "    filename = f'UCI HAR Dataset/{subset}/y_{subset}.txt'\n",
        "    y = _read_csv(filename)[0]\n",
        "\n",
        "    return pd.get_dummies(y).as_matrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXBkiekRsOxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utility function to read the data from csv file\n",
        "def _read_csv(filename):\n",
        "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
        "\n",
        "# Utility function to load the load\n",
        "def load_signals(subset):\n",
        "    signals_data = []\n",
        "\n",
        "    for signal in SIGNALS:\n",
        "        filename = f'UCI HAR Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
        "        signals_data.append(\n",
        "            _read_csv(filename).as_matrix()\n",
        "        ) \n",
        "\n",
        "    # Transpose is used to change the dimensionality of the output,\n",
        "    # aggregating the signals by combination of sample/timestep.\n",
        "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
        "    return np.transpose(signals_data, (1, 2, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPj5MYVusG6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    \"\"\"\n",
        "    Obtain the dataset from multiple files.\n",
        "    Returns: X_train, X_test, y_train, y_test\n",
        "    \"\"\"\n",
        "    X_train, X_test = load_signals('train'), load_signals('test')\n",
        "    y_train, y_test = load_y('train'), load_y('test')\n",
        "\n",
        "    return X_train, y_train, X_test,  y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2gTcNSvuv81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utility function to count the number of classes\n",
        "def _count_classes(y):\n",
        "    return len(set([tuple(category) for category in y]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzjo9866kA_d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ecb4b925-fc8f-4bd6-f7ef-570167320f92"
      },
      "source": [
        "# Loading the train and test data\n",
        "X_train, Y_train, X_test,  Y_test = load_data()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}